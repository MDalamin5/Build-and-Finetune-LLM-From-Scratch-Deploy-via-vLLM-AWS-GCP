# ğŸ§  Build LLM from Scratch

A comprehensive end-to-end repository documenting the entire process of **building a Large Language Model (LLM) from scratch** and mastering **deep learning with PyTorch**. This repo combines two powerful learning tracks:

* **Vizuara's "Building LLMs From Scratch" series**
* **CampusX's "Practical Deep Learning using PyTorch" series**

Whether you're a beginner or advancing your AI engineering skills, this repo gives you theory, code, experiments, and practical projects.

---

## ğŸš€ What You Will Learn

### **ğŸ”¹ LLM From Scratch (Vizuara Series)**

* LLM basics & architecture
* Tokenizers (BPE), datasets, dataloaders
* Transformer architecture & attention mechanism
* Embeddings, positional encodings, layer norms, GELU
* Multi-head attention, residual connections
* Coding GPT-like models in PyTorch
* Pretraining loop implementation
* Next-token prediction and sampling
* Loading GPTâ€‘2 weights & finetuning (classification + instruction)

### **ğŸ”¹ PyTorch Deep Learning (CampusX Series)**

* Tensor operations & autograd
* Full training pipeline in PyTorch
* Custom datasets & dataloaders
* Neural networks (ANN, CNN, RNN, LSTM)
* GPU training
* Optimization & hyperparameter tuning with Optuna
* Transfer learning
* Building real ML projects end-to-end

---

## ğŸ“ Repository Structure

```
ğŸ“¦ llm-pytorch-learning
â”‚
â”œâ”€â”€ llm_from_scratch/
â”‚   â”œâ”€â”€ tokenizer/
â”‚   â”œâ”€â”€ attention/
â”‚   â”œâ”€â”€ transformer/
â”‚   â”œâ”€â”€ gpt2/
â”‚   â”œâ”€â”€ training/
â”‚   â””â”€â”€ sampling/
â”‚
â”œâ”€â”€ pytorch_foundations/
â”‚   â”œâ”€â”€ tensors/
â”‚   â”œâ”€â”€ autograd/
â”‚   â”œâ”€â”€ ann/
â”‚   â”œâ”€â”€ cnn/
â”‚   â”œâ”€â”€ rnn_lstm/
â”‚   â””â”€â”€ transfer_learning/
â”‚
â”œâ”€â”€ projects/
â”‚   â”œâ”€â”€ text-classification/
â”‚   â”œâ”€â”€ next-word-prediction/
â”‚   â””â”€â”€ instruction-finetuning/
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“š Playlists Used

* **Building LLMs From Scratch (Vizuara)**
* **Practical Deep Learning using PyTorch (CampusX)**

---

## ğŸ’¡ Goals of This Repository

* Build intuition for modern LLMs
* Learn every component of GPT-like models
* Reinforce PyTorch fundamentals with real coding
* Practice clean, modular AI development
* Create your own working LLM training pipeline

---

## ğŸ›  Requirements

* Python 3.10+
* PyTorch
* NumPy
* tqdm
* Jupyter Notebook (optional)

Install with:

```bash
pip install torch numpy tqdm
```

---

## ğŸ§ª How to Use

Clone the repo:

```bash
git clone https://github.com/your-username/llm-pytorch-learning.git
cd llm-pytorch-learning
```

Run any module:

```bash
python llm_from_scratch/tokenizer/bpe_train.py
```

---

## ğŸ¤ Contributing

Pull requests are welcome! Feel free to suggest improvements or new experiment ideas.

---

## â­ Support the Project

If this repo helps you learn, consider giving it a **star** â­ on GitHub.

---

## ğŸ“¬ Contact

Maintainer: **Md Al Amin**

---

**Happy Learning!** ğŸš€
