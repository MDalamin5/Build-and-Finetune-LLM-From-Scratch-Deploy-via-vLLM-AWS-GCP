{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f21605e-5fdf-47e3-83a2-347e3cd73a36",
   "metadata": {},
   "source": [
    "## ***RNN using PyTorch***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e935e874-0631-4880-8ca8-1e28e7fafba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"100_Unique_QA_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1564c5ea-fd78-404c-b9c3-1035298fa54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Who discovered penicillin?</td>\n",
       "      <td>Alexander-Fleming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Which bird is known for its ability to mimic s...</td>\n",
       "      <td>Parrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Which sea creature has eight arms?</td>\n",
       "      <td>Octopus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question             answer\n",
       "26                         Who discovered penicillin?  Alexander-Fleming\n",
       "46  Which bird is known for its ability to mimic s...             Parrot\n",
       "68                 Which sea creature has eight arms?            Octopus"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee083c5-c47b-4ed5-aefc-5fbc99b4fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenization\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"?\", \"\")\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e32b53e4-981a-40e8-b543-0ba0e72a0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vocab\n",
    "vocab = {\n",
    "    \"<UNK>\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088f1244-411e-4ccb-b16f-cfef3e1c015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(row):\n",
    "    tok_ques = tokenize(row[\"question\"])\n",
    "    tok_ans = tokenize(row[\"answer\"])\n",
    "\n",
    "    merged_token = tok_ques + tok_ans\n",
    "    for token in merged_token:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)\n",
    "    # print(merged_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2d9ce5-d168-4af9-a0c1-b995bfabcac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert words to numerical\n",
    "df.apply(build_vocab, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bdd8ccf-a5ac-42c6-9eab-836865992979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b2cea-ce65-40e2-ad8d-c99f6d7be214",
   "metadata": {},
   "source": [
    "## **Text to Indexes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3f9f25-82df-4dfe-8c0b-ac6a46d0781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_index(text, vocab):\n",
    "    indexed_text = []\n",
    "    for token in tokenize(text):\n",
    "        if token in vocab:\n",
    "            indexed_text.append(vocab[token])\n",
    "        else: \n",
    "            indexed_text.append(vocab[\"<UNK>\"])\n",
    "    return indexed_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045d4dd5-5ee9-42f1-a899-09bdf13080eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 3, 6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_index(\"what is the capital of the france\", vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e422f-9bcf-42bd-a9f9-64db01d6c7c5",
   "metadata": {},
   "source": [
    "## **Build Custom Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff0c973-52bc-4148-8c70-1718f67e9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        numerical_question = text_to_index(self.df.iloc[index][\"question\"], self.vocab)\n",
    "        numerical_answer = text_to_index(self.df.iloc[index][\"answer\"], self.vocab)\n",
    "\n",
    "        return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e57a82-e8de-4522-aefd-1e7c725d6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(df, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2051f811-f525-4bea-a196-b64b62eee1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8107855-95a0-4869-843f-20f900eba007",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37b59b36-8f73-4e51-8336-82c1425085f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
      "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
      "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
      "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
      "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
      "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
      "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
      "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
      "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
      "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
      "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
      "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
      "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
      "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
      "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
      "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
      "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
      "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
      "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
      "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
      "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
      "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
      "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
      "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
      "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
      "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
      "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
      "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
      "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
      "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
      "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
      "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
      "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
      "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
      "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
      "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
      "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
      "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
      "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
      "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
      "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
      "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
      "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
      "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
      "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
      "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
      "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
      "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
      "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
      "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
      "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
      "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
      "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
      "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
      "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
      "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n",
      "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
      "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
      "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
      "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
      "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n",
      "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
      "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
      "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
      "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
      "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
      "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
      "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
      "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
      "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
      "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
      "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
      "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
      "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
      "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
      "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
      "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
      "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
      "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
      "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
      "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
      "tensor([[10, 75, 76]]) tensor([[77]])\n",
      "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
      "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n"
     ]
    }
   ],
   "source": [
    "for question, ans in dataloader:\n",
    "    print(question, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d35365c4-2a6f-4aae-be96-5cb802c1fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "\n",
    "  def __init__(self, vocab_size):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
    "    self.rnn = nn.RNN(50, 64, batch_first=True)\n",
    "    self.fc = nn.Linear(64, vocab_size)\n",
    "\n",
    "  def forward(self, question):\n",
    "    embedded_question = self.embedding(question)\n",
    "    hidden, final = self.rnn(embedded_question)\n",
    "    output = self.fc(final.squeeze(0))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c81cbea-b22b-4bbd-92aa-41600f629adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1de7973d-1ac2-4365-abec-54ef602bb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySimpleRNN(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06b9cd37-63c9-4849-b5f8-c26fc26f49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "683c3a16-063a-40ee-8244-b8df288d9dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 13.214156\n",
      "Epoch: 2, Loss: 8.033299\n",
      "Epoch: 3, Loss: 5.861472\n",
      "Epoch: 4, Loss: 4.452330\n",
      "Epoch: 5, Loss: 3.438008\n",
      "Epoch: 6, Loss: 2.737243\n",
      "Epoch: 7, Loss: 2.247586\n",
      "Epoch: 8, Loss: 1.871109\n",
      "Epoch: 9, Loss: 1.585633\n",
      "Epoch: 10, Loss: 1.361648\n",
      "Epoch: 11, Loss: 1.182876\n",
      "Epoch: 12, Loss: 1.030466\n",
      "Epoch: 13, Loss: 0.909487\n",
      "Epoch: 14, Loss: 0.806477\n",
      "Epoch: 15, Loss: 0.721072\n",
      "Epoch: 16, Loss: 0.647593\n",
      "Epoch: 17, Loss: 0.584644\n",
      "Epoch: 18, Loss: 0.530762\n",
      "Epoch: 19, Loss: 0.482753\n",
      "Epoch: 20, Loss: 0.440604\n",
      "Epoch: 21, Loss: 0.404118\n",
      "Epoch: 22, Loss: 0.371548\n",
      "Epoch: 23, Loss: 0.341326\n",
      "Epoch: 24, Loss: 0.315755\n",
      "Epoch: 25, Loss: 0.291667\n",
      "Epoch: 26, Loss: 0.271181\n",
      "Epoch: 27, Loss: 0.251649\n",
      "Epoch: 28, Loss: 0.234392\n",
      "Epoch: 29, Loss: 0.218223\n",
      "Epoch: 30, Loss: 0.203594\n",
      "Epoch: 31, Loss: 0.190334\n",
      "Epoch: 32, Loss: 0.178236\n",
      "Epoch: 33, Loss: 0.167207\n",
      "Epoch: 34, Loss: 0.156478\n",
      "Epoch: 35, Loss: 0.147270\n",
      "Epoch: 36, Loss: 0.138206\n",
      "Epoch: 37, Loss: 0.130171\n",
      "Epoch: 38, Loss: 0.122478\n",
      "Epoch: 39, Loss: 0.115611\n",
      "Epoch: 40, Loss: 0.108765\n",
      "Epoch: 41, Loss: 0.102871\n",
      "Epoch: 42, Loss: 0.097097\n",
      "Epoch: 43, Loss: 0.091728\n",
      "Epoch: 44, Loss: 0.086664\n",
      "Epoch: 45, Loss: 0.082048\n",
      "Epoch: 46, Loss: 0.077651\n",
      "Epoch: 47, Loss: 0.073649\n",
      "Epoch: 48, Loss: 0.069694\n",
      "Epoch: 49, Loss: 0.066057\n",
      "Epoch: 50, Loss: 0.062667\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  total_loss = 0\n",
    "\n",
    "  for question, answer in dataloader:\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    output = model(question)\n",
    "\n",
    "    # loss -> output shape (1,324) - (1)\n",
    "    loss = criterion(output, answer[0])\n",
    "\n",
    "    # gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9ee135e-a4b2-4fae-9bb4-bf98171536bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, question, threshold=0.5):\n",
    "\n",
    "  # convert question to numbers\n",
    "  numerical_question = text_to_index(question, vocab)\n",
    "\n",
    "  # tensor\n",
    "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
    "\n",
    "  # send to model\n",
    "  output = model(question_tensor)\n",
    "\n",
    "  # convert logits to probs\n",
    "  probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "  # find index of max prob\n",
    "  value, index = torch.max(probs, dim=1)\n",
    "\n",
    "  if value < threshold:\n",
    "    print(\"I don't know\")\n",
    "\n",
    "  print(list(vocab.keys())[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75f95150-fcf9-4dd5-a292-b66c05cca7b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_to_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the largest planet in our solar system?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, question, threshold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(model, question, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# convert question to numbers\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m   numerical_question \u001b[38;5;241m=\u001b[39m \u001b[43mtext_to_indices\u001b[49m(question, vocab)\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;66;03m# tensor\u001b[39;00m\n\u001b[1;32m      7\u001b[0m   question_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(numerical_question)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_to_indices' is not defined"
     ]
    }
   ],
   "source": [
    "predict(model, \"What is the largest planet in our solar system?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
