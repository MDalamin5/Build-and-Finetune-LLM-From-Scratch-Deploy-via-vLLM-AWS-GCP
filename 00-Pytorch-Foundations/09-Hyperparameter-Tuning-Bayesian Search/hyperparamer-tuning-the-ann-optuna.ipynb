{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f2bae7-9fbe-4a8b-9a0b-59779ba40041",
   "metadata": {},
   "source": [
    "## **HyperParametr Tuning using Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b33afd-e316-41cd-9a1c-cea39ab86cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d6f3c3-8ea3-4154-8f93-c46879b6153c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x71cc40759250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1eccb3-2f0f-410d-b036-ecc694c78d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3733ef-01c3-4438-b808-6e49dc9860ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4986e98-f310-4f67-b006-e40c478fb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1: ].values\n",
    "y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59520c8c-15d3-4c78-afcc-31739836dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e56485-079e-4898-93a1-015e4c90bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the features\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155cef5-08a1-4ee5-b799-761dc7a49c03",
   "metadata": {},
   "source": [
    "## **Our Custome Dataset and DataLoader Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28ed2ab-992f-4cd2-a59c-6b5dfeca755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, features, lable):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.lable = torch.tensor(lable, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.lable[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e38f476-9fd0-4550-9253-0ac312547228",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyCustomDataset(X_train, y_train)\n",
    "test_dataset = MyCustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c3a16-6f8e-4ffd-ae96-671702d759b4",
   "metadata": {},
   "source": [
    "## **DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c80f2f8-4fcf-41c9-b2d2-f238dfa83115",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4ee37-4fd5-4d30-a240-5a402cd9f65f",
   "metadata": {},
   "source": [
    "## **Tuning On only Nuron and Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09e94591-ddb6-4170-bec6-9f98e8d60bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_hidden_layers, neurons_per_layer):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_hidden_layers):\n",
    "            layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
    "            layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.3))\n",
    "            input_dim = neurons_per_layer\n",
    "\n",
    "        layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "488c09c4-72a2-4a94-8d64-898d7c762115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # next hyperparameter values from the search space\n",
    "    num_hidden_layer = trial.suggest_int(\"neuron_per_layer\", 1, 5)\n",
    "    neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 8, 128, step=8)\n",
    "\n",
    "    # model init\n",
    "    input_dim = 784\n",
    "    output_dim = 10\n",
    "\n",
    "    model = MyNN(input_dim, output_dim, num_hidden_layer, neurons_per_layer)\n",
    "    model.to(device)\n",
    "\n",
    "    # params init\n",
    "    learning_rate = 0.01\n",
    "    epochs = 50\n",
    "\n",
    "    loss_functions = nn.CrossEntropyLoss()\n",
    "\n",
    "    ## optimizer\n",
    "    optimzer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    # training loop\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_epoch_loss = 0\n",
    "        for batch_features, batch_labels in train_dataloader:\n",
    "            ## move dataset into the gpu\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "            ## forward\n",
    "            output = model(batch_features)\n",
    "    \n",
    "            ## loss\n",
    "            loss = loss_functions(output, batch_labels)\n",
    "    \n",
    "            ## backward\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "    \n",
    "            ## update the weight\n",
    "            optimzer.step()\n",
    "    \n",
    "        #     total_epoch_loss = total_epoch_loss + loss.item()\n",
    "    \n",
    "        # avg_loss = total_epoch_loss/len(train_dataloader)\n",
    "        # print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')\n",
    "    # evaluations\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "      for batch_features, batch_labels in test_dataloader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "    \n",
    "        outputs = model(batch_features)\n",
    "        # print(outputs[0])\n",
    "    \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # print(predicted)\n",
    "    \n",
    "        total = total + batch_labels.shape[0]\n",
    "        # print((predicted == batch_labels).sum().item())\n",
    "    \n",
    "        correct = correct + (predicted == batch_labels).sum().item()\n",
    "        # break\n",
    "    \n",
    "    accuracy = correct/total\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa22695b-e8f3-485f-8d23-8ff82f7c7693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 15:48:16,440] A new study created in memory with name: no-name-f9fd3f27-b813-4d93-a660-0ebaa42b56c5\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "515ea577-ddc5-4e85-b5cb-5f55186d8ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 15:50:39,998] Trial 0 finished with value: 0.868 and parameters: {'neuron_per_layer': 2, 'neurons_per_layer': 120}. Best is trial 0 with value: 0.868.\n",
      "[I 2025-11-26 15:52:39,401] Trial 1 finished with value: 0.8473333333333334 and parameters: {'neuron_per_layer': 4, 'neurons_per_layer': 80}. Best is trial 0 with value: 0.868.\n",
      "[I 2025-11-26 15:54:33,414] Trial 2 finished with value: 0.8603333333333333 and parameters: {'neuron_per_layer': 4, 'neurons_per_layer': 128}. Best is trial 0 with value: 0.868.\n",
      "[I 2025-11-26 15:56:26,658] Trial 3 finished with value: 0.85225 and parameters: {'neuron_per_layer': 4, 'neurons_per_layer': 88}. Best is trial 0 with value: 0.868.\n",
      "[I 2025-11-26 15:58:40,654] Trial 4 finished with value: 0.7073333333333334 and parameters: {'neuron_per_layer': 5, 'neurons_per_layer': 24}. Best is trial 0 with value: 0.868.\n",
      "[I 2025-11-26 16:00:59,428] Trial 5 finished with value: 0.8571666666666666 and parameters: {'neuron_per_layer': 3, 'neurons_per_layer': 96}. Best is trial 0 with value: 0.868.\n",
      "[I 2025-11-26 16:02:39,207] Trial 6 finished with value: 0.8575833333333334 and parameters: {'neuron_per_layer': 2, 'neurons_per_layer': 88}. Best is trial 0 with value: 0.868.\n",
      "[I 2025-11-26 16:05:09,186] Trial 7 finished with value: 0.8571666666666666 and parameters: {'neuron_per_layer': 5, 'neurons_per_layer': 128}. Best is trial 0 with value: 0.868.\n",
      "[I 2025-11-26 16:07:37,947] Trial 8 finished with value: 0.8560833333333333 and parameters: {'neuron_per_layer': 4, 'neurons_per_layer': 104}. Best is trial 0 with value: 0.868.\n",
      "[I 2025-11-26 16:09:40,284] Trial 9 finished with value: 0.82325 and parameters: {'neuron_per_layer': 3, 'neurons_per_layer': 40}. Best is trial 0 with value: 0.868.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88f1125d-1dce-4c65-bced-ee98e7116b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7759b8-de5c-492b-802d-811024011791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neuron_per_layer': 2, 'neurons_per_layer': 120}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe781162-f0e9-4502-90a2-3f731167565a",
   "metadata": {},
   "source": [
    "## ***Tuning on `all` hyper params***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c75040a-c7d7-4542-9165-2b39ffe71a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_hidden_layers):\n",
    "            layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
    "            layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = neurons_per_layer\n",
    "\n",
    "        layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1042603-3c9f-42b6-a5c2-563d0244d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # next hyperparameter values from the search space\n",
    "    num_hidden_layer = trial.suggest_int(\"num_hidden_layers\", 1, 5)\n",
    "    neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 8, 128, step=8)\n",
    "    epochs = trial.suggest_int(\"epochs\", 10, 50, step=10)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_name\", [\"Adam\", \"SDG\", \"RMSprop\"])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "\n",
    "    # model init\n",
    "    input_dim = 784\n",
    "    output_dim = 10\n",
    "\n",
    "    model = MyNN(input_dim, output_dim, num_hidden_layer, neurons_per_layer, dropout_rate)\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "    loss_functions = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "    # training loop\n",
    "\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimzer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "    elif optimizer_name == \"SDG\":\n",
    "        optimzer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "    elif optimizer_name == \"RMSprop\":\n",
    "        optimzer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_epoch_loss = 0\n",
    "        for batch_features, batch_labels in train_dataloader:\n",
    "            ## move dataset into the gpu\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "            ## forward\n",
    "            output = model(batch_features)\n",
    "    \n",
    "            ## loss\n",
    "            loss = loss_functions(output, batch_labels)\n",
    "    \n",
    "            ## backward\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "    \n",
    "            ## update the weight\n",
    "            optimzer.step()\n",
    "    \n",
    "        #     total_epoch_loss = total_epoch_loss + loss.item()\n",
    "    \n",
    "        # avg_loss = total_epoch_loss/len(train_dataloader)\n",
    "        # print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')\n",
    "    # evaluations\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "      for batch_features, batch_labels in test_dataloader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "    \n",
    "        outputs = model(batch_features)\n",
    "        # print(outputs[0])\n",
    "    \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # print(predicted)\n",
    "    \n",
    "        total = total + batch_labels.shape[0]\n",
    "        # print((predicted == batch_labels).sum().item())\n",
    "    \n",
    "        correct = correct + (predicted == batch_labels).sum().item()\n",
    "        # break\n",
    "    \n",
    "    accuracy = correct/total\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97f13e31-0ac5-4b74-abb9-abe12ee0c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 16:51:27,293] A new study created in memory with name: no-name-a9111000-7846-4665-928d-0538de776803\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ef1c76f-3c29-4fb7-9e3c-1cdc3528e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 16:51:38,945] Trial 0 finished with value: 0.7590833333333333 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 96, 'epochs': 10, 'learning_rate': 0.04458321513949984, 'dropout_rate': 0.2, 'batch_size': 128, 'optimizer_name': 'RMSprop', 'weight_decay': 9.205806940403789e-05}. Best is trial 0 with value: 0.7590833333333333.\n",
      "[I 2025-11-26 16:52:18,338] Trial 1 finished with value: 0.83425 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 32, 'epochs': 40, 'learning_rate': 2.990397209874006e-05, 'dropout_rate': 0.1, 'batch_size': 128, 'optimizer_name': 'RMSprop', 'weight_decay': 0.000330783071229359}. Best is trial 1 with value: 0.83425.\n",
      "[I 2025-11-26 16:52:56,187] Trial 2 finished with value: 0.5115833333333333 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 64, 'epochs': 30, 'learning_rate': 3.751129669540892e-05, 'dropout_rate': 0.30000000000000004, 'batch_size': 64, 'optimizer_name': 'SDG', 'weight_decay': 1.4905819878715933e-05}. Best is trial 1 with value: 0.83425.\n",
      "[I 2025-11-26 16:53:15,701] Trial 3 finished with value: 0.7893333333333333 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 16, 'epochs': 10, 'learning_rate': 1.555481432858363e-05, 'dropout_rate': 0.1, 'batch_size': 32, 'optimizer_name': 'RMSprop', 'weight_decay': 3.879077006085273e-05}. Best is trial 1 with value: 0.83425.\n",
      "[I 2025-11-26 16:54:35,849] Trial 4 finished with value: 0.7808333333333334 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 48, 'epochs': 30, 'learning_rate': 0.042732979539022255, 'dropout_rate': 0.1, 'batch_size': 32, 'optimizer_name': 'Adam', 'weight_decay': 1.1304115636032568e-05}. Best is trial 1 with value: 0.83425.\n",
      "[I 2025-11-26 16:56:00,099] Trial 5 finished with value: 0.6435 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 48, 'epochs': 50, 'learning_rate': 0.007997343104355247, 'dropout_rate': 0.5, 'batch_size': 64, 'optimizer_name': 'SDG', 'weight_decay': 0.00019632443187053722}. Best is trial 1 with value: 0.83425.\n",
      "[I 2025-11-26 16:56:09,386] Trial 6 finished with value: 0.8633333333333333 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 96, 'epochs': 10, 'learning_rate': 0.0013787340896939183, 'dropout_rate': 0.2, 'batch_size': 128, 'optimizer_name': 'Adam', 'weight_decay': 1.2828695780026723e-05}. Best is trial 6 with value: 0.8633333333333333.\n",
      "[I 2025-11-26 16:57:49,345] Trial 7 finished with value: 0.8515833333333334 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 32, 'epochs': 40, 'learning_rate': 0.0010187472718115914, 'dropout_rate': 0.1, 'batch_size': 32, 'optimizer_name': 'RMSprop', 'weight_decay': 1.3486314228337458e-05}. Best is trial 6 with value: 0.8633333333333333.\n",
      "[I 2025-11-26 16:59:49,854] Trial 8 finished with value: 0.8334166666666667 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 112, 'epochs': 30, 'learning_rate': 0.00027703474710607135, 'dropout_rate': 0.5, 'batch_size': 16, 'optimizer_name': 'Adam', 'weight_decay': 4.2650111990766554e-05}. Best is trial 6 with value: 0.8633333333333333.\n",
      "[I 2025-11-26 17:01:29,933] Trial 9 finished with value: 0.7695 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 40, 'epochs': 30, 'learning_rate': 0.013231200002441013, 'dropout_rate': 0.2, 'batch_size': 16, 'optimizer_name': 'RMSprop', 'weight_decay': 0.00032992590296822467}. Best is trial 6 with value: 0.8633333333333333.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0475e9-f816-4b13-88b5-90adcee16d55",
   "metadata": {},
   "source": [
    "## **To improve more**\n",
    "- use more trail\n",
    "- use more logn parameter range as `search range`\n",
    "- Use MLflow to track the experiments and log each trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7039451e-e1c8-4c64-b40e-013dfec98016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_hidden_layers': 5,\n",
       " 'neurons_per_layer': 96,\n",
       " 'epochs': 10,\n",
       " 'learning_rate': 0.0013787340896939183,\n",
       " 'dropout_rate': 0.2,\n",
       " 'batch_size': 128,\n",
       " 'optimizer_name': 'Adam',\n",
       " 'weight_decay': 1.2828695780026723e-05}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16082c2-a762-4d27-8b4b-20ba7a0b66ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
